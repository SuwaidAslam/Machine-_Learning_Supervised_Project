{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CE802_P2_Notebook.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FDig9829O3vY"
      },
      "source": [
        "# Import libraries \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x_dL1IBaFHYG"
      },
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import sklearn.metrics as metrics"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MKC5yvpSJrRv"
      },
      "source": [
        "# Import Datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZO_bJntFJudn"
      },
      "source": [
        "# Loading Train Data\n",
        "df_train = pd.read_csv(\"CE802_P2_Data.csv\")\n",
        "# Loading Train Data\n",
        "df_test = pd.read_csv(\"CE802_P2_Test.csv\")"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1il7tmv9LtbZ"
      },
      "source": [
        "# Exploratory data analysis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "id": "3yAcj-niKpyZ",
        "outputId": "08463130-6eb5-4a34-e6c9-5a7ce1c61161"
      },
      "source": [
        "df_train.head()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>F1</th>\n",
              "      <th>F2</th>\n",
              "      <th>F3</th>\n",
              "      <th>F4</th>\n",
              "      <th>F5</th>\n",
              "      <th>F6</th>\n",
              "      <th>F7</th>\n",
              "      <th>F8</th>\n",
              "      <th>F9</th>\n",
              "      <th>F10</th>\n",
              "      <th>F11</th>\n",
              "      <th>F12</th>\n",
              "      <th>F13</th>\n",
              "      <th>F14</th>\n",
              "      <th>F15</th>\n",
              "      <th>Class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>30</td>\n",
              "      <td>186.88</td>\n",
              "      <td>-21.06</td>\n",
              "      <td>-17.68</td>\n",
              "      <td>14.20</td>\n",
              "      <td>563.22</td>\n",
              "      <td>-3.29</td>\n",
              "      <td>-5.32</td>\n",
              "      <td>-18.90</td>\n",
              "      <td>9.20</td>\n",
              "      <td>-9.44</td>\n",
              "      <td>10.89</td>\n",
              "      <td>-8.54</td>\n",
              "      <td>510</td>\n",
              "      <td>NaN</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>30</td>\n",
              "      <td>196.88</td>\n",
              "      <td>-22.89</td>\n",
              "      <td>-19.38</td>\n",
              "      <td>19.70</td>\n",
              "      <td>353.22</td>\n",
              "      <td>-5.71</td>\n",
              "      <td>-1.48</td>\n",
              "      <td>-18.33</td>\n",
              "      <td>7.15</td>\n",
              "      <td>-8.58</td>\n",
              "      <td>15.89</td>\n",
              "      <td>-8.44</td>\n",
              "      <td>760</td>\n",
              "      <td>7.22</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>30</td>\n",
              "      <td>96.88</td>\n",
              "      <td>-19.65</td>\n",
              "      <td>-16.46</td>\n",
              "      <td>17.30</td>\n",
              "      <td>398.22</td>\n",
              "      <td>-5.19</td>\n",
              "      <td>-1.96</td>\n",
              "      <td>-14.64</td>\n",
              "      <td>7.10</td>\n",
              "      <td>-9.18</td>\n",
              "      <td>20.89</td>\n",
              "      <td>-8.79</td>\n",
              "      <td>610</td>\n",
              "      <td>7.69</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>216.88</td>\n",
              "      <td>-33.24</td>\n",
              "      <td>-27.80</td>\n",
              "      <td>0.84</td>\n",
              "      <td>344.22</td>\n",
              "      <td>-0.86</td>\n",
              "      <td>-6.89</td>\n",
              "      <td>-14.73</td>\n",
              "      <td>0.09</td>\n",
              "      <td>-17.98</td>\n",
              "      <td>7.89</td>\n",
              "      <td>-3.78</td>\n",
              "      <td>32</td>\n",
              "      <td>NaN</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3</td>\n",
              "      <td>198.88</td>\n",
              "      <td>-32.52</td>\n",
              "      <td>-26.26</td>\n",
              "      <td>1.52</td>\n",
              "      <td>278.22</td>\n",
              "      <td>0.08</td>\n",
              "      <td>-7.73</td>\n",
              "      <td>-13.62</td>\n",
              "      <td>1.91</td>\n",
              "      <td>-23.94</td>\n",
              "      <td>7.89</td>\n",
              "      <td>-3.25</td>\n",
              "      <td>36</td>\n",
              "      <td>NaN</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   F1      F2     F3     F4     F5  ...    F12   F13  F14   F15  Class\n",
              "0  30  186.88 -21.06 -17.68  14.20  ...  10.89 -8.54  510   NaN  False\n",
              "1  30  196.88 -22.89 -19.38  19.70  ...  15.89 -8.44  760  7.22  False\n",
              "2  30   96.88 -19.65 -16.46  17.30  ...  20.89 -8.79  610  7.69  False\n",
              "3   3  216.88 -33.24 -27.80   0.84  ...   7.89 -3.78   32   NaN  False\n",
              "4   3  198.88 -32.52 -26.26   1.52  ...   7.89 -3.25   36   NaN   True\n",
              "\n",
              "[5 rows x 16 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_R7sbBjBKp1G",
        "outputId": "a96fa8a4-5bbf-4e0a-f019-4139472d6a96"
      },
      "source": [
        "df_train.shape"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1500, 16)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HItopwm1OYWF",
        "outputId": "143a46ba-8795-4405-dc62-70811a71ee3f"
      },
      "source": [
        "df_train.columns"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['F1', 'F2', 'F3', 'F4', 'F5', 'F6', 'F7', 'F8', 'F9', 'F10', 'F11',\n",
              "       'F12', 'F13', 'F14', 'F15', 'Class'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-07uka-iPMZt",
        "outputId": "36959d80-e4f3-4a6d-d6c4-a94a09645407"
      },
      "source": [
        "df_train.info()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1500 entries, 0 to 1499\n",
            "Data columns (total 16 columns):\n",
            " #   Column  Non-Null Count  Dtype  \n",
            "---  ------  --------------  -----  \n",
            " 0   F1      1500 non-null   int64  \n",
            " 1   F2      1500 non-null   float64\n",
            " 2   F3      1500 non-null   float64\n",
            " 3   F4      1500 non-null   float64\n",
            " 4   F5      1500 non-null   float64\n",
            " 5   F6      1500 non-null   float64\n",
            " 6   F7      1500 non-null   float64\n",
            " 7   F8      1500 non-null   float64\n",
            " 8   F9      1500 non-null   float64\n",
            " 9   F10     1500 non-null   float64\n",
            " 10  F11     1500 non-null   float64\n",
            " 11  F12     1500 non-null   float64\n",
            " 12  F13     1500 non-null   float64\n",
            " 13  F14     1500 non-null   int64  \n",
            " 14  F15     750 non-null    float64\n",
            " 15  Class   1500 non-null   bool   \n",
            "dtypes: bool(1), float64(13), int64(2)\n",
            "memory usage: 177.4 KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pdd6lUq7Mr-H"
      },
      "source": [
        "# Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HjdL4yixLyeM"
      },
      "source": [
        "# drping entire row that has nan value\n",
        "df_train.dropna(subset=['F15'], axis=0,inplace= True)\n",
        "df_test.dropna(subset=['F15'], axis=0,inplace= True)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wb86hOBtMd-H",
        "outputId": "38b5f097-ec2f-48da-ce6c-ab1968152b8d"
      },
      "source": [
        "df_train.shape"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(750, 16)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IsQeKlVsNNzf"
      },
      "source": [
        "# Spliting our dataset into Training and Validation sets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ie6b0TshMf_2"
      },
      "source": [
        "# Set variables for the targets and features\n",
        "X = df_train.drop('Class', axis=1)\n",
        "y = df_train['Class']\n",
        "\n",
        "# Split the data into training and validation sets\n",
        "train_X, val_X, train_y, val_y = train_test_split(X, y, test_size=0.2, random_state=7)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0u8agyPoOqbU"
      },
      "source": [
        "# Decision Tree Classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bcbUP-lQOM1O"
      },
      "source": [
        "# import DecisionTreeClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "utTyEO4NPr6s",
        "outputId": "2f6eef34-d321-4e6b-df7a-cdd9dbc1747a"
      },
      "source": [
        "# instantiate the DecisionTreeClassifier model\n",
        "clf_dt = DecisionTreeClassifier(criterion='entropy', max_depth=3, random_state=0)\n",
        "\n",
        "# fit the model\n",
        "clf_dt.fit(train_X, train_y)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='entropy',\n",
              "                       max_depth=3, max_features=None, max_leaf_nodes=None,\n",
              "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                       min_samples_leaf=1, min_samples_split=2,\n",
              "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
              "                       random_state=0, splitter='best')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iOTX8lYEQ87L",
        "outputId": "b127bdae-daf3-4eb2-b518-d0796fa67bac"
      },
      "source": [
        "# Predict classes given the validation features\n",
        "pred_y = clf_dt.predict(val_X)\n",
        "\n",
        "# Calculate the accuracy as our performance metric\n",
        "accuracy = metrics.accuracy_score(val_y, pred_y)\n",
        "accuracy_scores = []\n",
        "accuracy_scores.append(accuracy)\n",
        "print(\"Accuracy: \", accuracy)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy:  0.86\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VntK97VVTkyI"
      },
      "source": [
        "# Random Forest Classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q-UQnr6KU01Y"
      },
      "source": [
        "# import RandomForestClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tizD1W4LR-02",
        "outputId": "87cc1327-1322-421b-d31a-c70161b59daa"
      },
      "source": [
        "# Create the Random forest classifier and fit it to our training data\n",
        "cld_rf = RandomForestClassifier(random_state=7, n_estimators=100)\n",
        "\n",
        "cld_rf.fit(train_X, train_y)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
              "                       criterion='gini', max_depth=None, max_features='auto',\n",
              "                       max_leaf_nodes=None, max_samples=None,\n",
              "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                       min_samples_leaf=1, min_samples_split=2,\n",
              "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
              "                       n_jobs=None, oob_score=False, random_state=7, verbose=0,\n",
              "                       warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FTvvDmCEUl2t",
        "outputId": "4305a061-909b-49ef-df0b-665c19fe0448"
      },
      "source": [
        "# Predict classes given the validation features\n",
        "pred_y = cld_rf.predict(val_X)\n",
        "\n",
        "# Calculate the accuracy as our performance metric\n",
        "accuracy = metrics.accuracy_score(val_y, pred_y)\n",
        "accuracy_scores.append(accuracy)\n",
        "print(\"Accuracy: \", accuracy)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy:  0.8866666666666667\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MC0BbiH_V3tO"
      },
      "source": [
        "# Logistic Regression Classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yW7ogw55VZRU"
      },
      "source": [
        "# import LogisticRegression\n",
        "from sklearn.linear_model import LogisticRegression"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "szzpC1jiWgVd"
      },
      "source": [
        "#### Feature Scaling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ZFLqSQpWeyE"
      },
      "source": [
        "# data scaling with sklearn\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# fit scaler on training data\n",
        "scal = StandardScaler().fit(train_X)\n",
        "\n",
        "# transform training data\n",
        "X_train_scal = scal.transform(train_X)\n",
        "\n",
        "# transform validation dataabs\n",
        "X_val_scal = scal.transform(val_X)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sAW_v2INXdOR",
        "outputId": "2a1e781a-0aad-4a86-cf79-d37284af6290"
      },
      "source": [
        "# Create the LogisticRegression classifier and fit it to our training data\n",
        "cld_lr = LogisticRegression()\n",
        "\n",
        "cld_lr.fit(X_train_scal, train_y)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
              "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
              "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
              "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                   warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "myk8tXlUX15u",
        "outputId": "e9e1e726-0130-4a2d-b66b-0bbd0d7c1cf8"
      },
      "source": [
        "# Predict classes given the validation features\n",
        "pred_y = cld_lr.predict(X_val_scal)\n",
        "\n",
        "# Calculate the accuracy as our performance metric\n",
        "accuracy = metrics.accuracy_score(val_y, pred_y)\n",
        "accuracy_scores.append(accuracy)\n",
        "print(\"Accuracy: \", accuracy)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy:  0.9133333333333333\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ulQBCvOUkhIu"
      },
      "source": [
        "# Models Score Plot"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w5X5Zw-gkl2h"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 352
        },
        "id": "o5ZrG64kkoCN",
        "outputId": "84a779ab-ac82-4a68-c115-243491b6db9e"
      },
      "source": [
        "models = ['Decision Tree', 'Random Forest', 'Logistic Regression']\n",
        "fig = plt.figure()\n",
        "ax = fig.add_axes([0,0,1,1])\n",
        "ax.bar(models,accuracy_scores)\n",
        "ax.set_ylabel('Accuracy Score')\n",
        "ax.set_title('Models')\n",
        "plt.show()"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeMAAAFPCAYAAAB+qaatAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAbc0lEQVR4nO3de5hddX3v8feHAAJykZpoqUCCFlTUihrxWqWKFm9wWqlCtYj1SO0RrNdHPFqL9HJQ612oQrVQKkVAyolKRUVQS7US5CIJxWKUAvIcgoIIigh8zx9rjWzGSbJjZuU3k/1+Pc88s9ZvXfZ371mzP/u3bjtVhSRJamez1gVIkjTpDGNJkhozjCVJaswwliSpMcNYkqTGDGNJkhozjCX9QpIlSSrJ5mPMe2iSf9sYdUmbOsNYmseSfC/JHUkWTmu/uA/VJW0qk7Q+DGNp/vsucPDUSJJHAdu0K0fS+jKMpfnvZOCQkfGXAf84NZJkhyT/mGR1kquTvC3JZv20BUn+NsmNSVYBzxtdcb/sx5Jcn+S6JH+VZMH0AtJ5X5IbktyS5FtJHjnM05U2PYaxNP99Hdg+ycP7oDwI+KeR6R8CdgAeDDydLrhf3k97JfB84DHAUuDAaes+EbgT+M1+nmcD/3OGGp4NPA3Yo3+sFwE/2MDnJU0Mw1jaNEz1jp8FXAFc17dPhfNbqurHVfU94D3AH/XTXwS8v6quqaofAv9naoVJHgg8F3htVd1WVTcA7+vXN93Pge2AhwGpqiuq6vpZfo7SJmudZ0xKmhdOBr4C7MbILmpgIbAFcPVI29XAg/rh3wCumTZtyuJ+2euTTLVtNm1+AKrqS0k+DBwLLE5yJvDGqrrlV31C0iSxZyxtAqrqaroTuZ4LnDky6Ua6XuvikbZduafnfD2wy7RpU64BfgYsrKr79T/bV9Uj1lDDB6vqccCedLur37QBT0maKIaxtOl4BfCMqrptpO0u4DTgr5Nsl2Qx8HruOaZ8GvCaJDsn2RE4cmrBfjfz54H3JNk+yWZJHpLk6dMfOMnjkzwhyRbAbcDtwN1DPElpU2QYS5uIqvpOVS2fYdIRdAG5Cvg34BTg4/20E4BzgEuBb3LvXjV0x6G3BFYCNwFnADvN8Bjb9+u6iW5X9w+Ad2/A05EmSqqqdQ2SJE00e8aSJDVmGEuS1JhhLElSY4axJEmNGcaSJDU27+7AtXDhwlqyZEnrMiRJWi8XXXTRjVW1aKZp8y6MlyxZwvLlM11KKUnS3JXk6jVNcze1JEmNGcaSJDVmGEuS1JhhLElSY4axJEmNGcaSJDVmGEuS1JhhLElSY4axJEmNGcaSJDVmGEuS1JhhLElSY/PuiyIkab5YcuRnW5egDfC9Y5630R7LnrEkSY0ZxpIkNWYYS5LUmGEsSVJjhrEkSY0ZxpIkNWYYS5LUmNcZS+vB60bnt4153ai0PuwZS5LUmGEsSVJjhrEkSY0ZxpIkNWYYS5LUmGEsSVJjhrEkSY1N/HXGXjc6v3ndqKRNgT1jSZIaM4wlSWrMMJYkqTHDWJKkxgxjSZIaM4wlSWrMMJYkqTHDWJKkxgxjSZIaM4wlSWrMMJYkqTHDWJKkxgxjSZIaGzSMk+yX5MokVyU5cobpuyY5L8nFSS5L8twh65EkaS4aLIyTLACOBZ4D7AkcnGTPabO9DTitqh4DHAQcN1Q9kiTNVUP2jPcGrqqqVVV1B3AqcMC0eQrYvh/eAfj+gPVIkjQnbT7guh8EXDMyfi3whGnzHAV8PskRwH2BfQesR5KkOan1CVwHAydW1c7Ac4GTk/xSTUkOS7I8yfLVq1dv9CIlSRrSkGF8HbDLyPjOfduoVwCnAVTV14CtgIXTV1RVx1fV0qpaumjRooHKlSSpjSHD+EJg9yS7JdmS7gStZdPm+W/gmQBJHk4XxnZ9JUkTZbAwrqo7gcOBc4Ar6M6aXpHk6CT797O9AXhlkkuBfwYOraoaqiZJkuaiIU/goqrOBs6e1vb2keGVwFOGrEGSpLmu9QlckiRNPMNYkqTGDGNJkhozjCVJaswwliSpMcNYkqTGDGNJkhozjCVJaswwliSpMcNYkqTGDGNJkhozjCVJaswwliSpMcNYkqTGDGNJkhozjCVJaswwliSpMcNYkqTGDGNJkhozjCVJaswwliSpMcNYkqTGDGNJkhozjCVJaswwliSpMcNYkqTGDGNJkhozjCVJaswwliSpMcNYkqTGDGNJkhozjCVJaswwliSpMcNYkqTGDGNJkhozjCVJaswwliSpMcNYkqTGDGNJkhozjCVJaswwliSpMcNYkqTGDGNJkhozjCVJaswwliSpMcNYkqTGDGNJkhozjCVJaswwliSpMcNYkqTGDGNJkhobNIyT7JfkyiRXJTlyDfO8KMnKJCuSnDJkPZIkzUWbD7XiJAuAY4FnAdcCFyZZVlUrR+bZHXgL8JSquinJA4aqR5KkuWrInvHewFVVtaqq7gBOBQ6YNs8rgWOr6iaAqrphwHokSZqTxg7jJNus57ofBFwzMn5t3zZqD2CPJBck+XqS/dbzMSRJmvfWGcZJnpxkJfCf/fijkxw3S4+/ObA7sA9wMHBCkvvNUMNhSZYnWb569epZemhJkuaGcXrG7wN+F/gBQFVdCjxtjOWuA3YZGd+5bxt1LbCsqn5eVd8Fvk0XzvdSVcdX1dKqWrpo0aIxHlqSpPljrN3UVXXNtKa7xljsQmD3JLsl2RI4CFg2bZ6z6HrFJFlIt9t61Tg1SZK0qRgnjK9J8mSgkmyR5I3AFetaqKruBA4HzunnP62qViQ5Osn+/WznAD/od4OfB7ypqn7wKz0TSZLmqXEubXoV8AG6k6+uAz4PvHqclVfV2cDZ09rePjJcwOv7H0mSJtJaw7i/VvgDVfWSjVSPJEkTZ627qavqLmBxf8xXkiQNYJzd1KuAC5IsA26baqyq9w5WlSRJE2ScMP5O/7MZsN2w5UiSNHnWGcZV9Q6AJNv247cOXZQkSZNknDtwPTLJxcAKYEWSi5I8YvjSJEmaDONcZ3w88PqqWlxVi4E3ACcMW5YkSZNjnDC+b1WdNzVSVecD9x2sIkmSJsxYZ1Mn+XPg5H78pXjLSkmSZs04PeM/BhYBZwKfAhb2bZIkaRaMczb1TcBrNkItkiRNpHHOpv7C6HcMJ9kxyTnDliVJ0uQYZzf1wqq6eWqk7yk/YLiSJEmaLOOE8d1Jdp0aSbIYqOFKkiRpsoxzNvVbgX9L8mUgwG8Dhw1alSRJE2ScE7g+l+SxwBPpesSvraobB69MkqQJscbd1EkWJ9kBoA/f24BnA4f4lYqSJM2etR0zPo3+TltJ9gJOB/4beDRw3PClSZI0Gda2m3rrqvp+P/xS4ONV9Z4kmwGXDF+aJEmTYW0944wMPwM4F6Cq7h60IkmSJszaesZfSnIacD2wI/AlgCQ7AXdshNokSZoIawvj1wIvBnYCnlpVP+/bf53ucidJkjQL1hjGVVXAqTO0XzxoRZIkTZhx7sAlSZIGZBhLktTYON/a9IL+ciZJkjSAcUL2xcB/JXlXkocNXZAkSZNmnWFcVS8FHgN8BzgxydeSHJZku8GrkyRpAoy1+7mqbgHOoDu7eifg94BvJjliwNokSZoI4xwz3j/JvwDnA1sAe1fVc+juUf2GYcuTJGnTN873Gb8QeF9VfWW0sap+kuQVw5QlSdLkGCeMj6K7JSYASbYGHlhV36uqc4cqTJKkSTHOMePTgdEvh7irb5MkSbNgnDDevKp+8cUQ/fCWw5UkSdJkGSeMVyfZf2okyQHAjcOVJEnSZBnnmPGrgE8k+TDddxxfAxwyaFWSJE2QdYZxVX0HeGKSbfvxWwevSpKkCTJOz5gkzwMeAWyVBICqOnrAuiRJmhjj3PTjI3T3pz6Cbjf1HwCLB65LkqSJMc4JXE+uqkOAm6rqHcCTgD2GLUuSpMkxThjf3v/+SZLfAH5Od39qSZI0C8Y5ZvzpJPcD3g18EyjghEGrkiRpgqw1jJNsBpxbVTcDn0ryGWCrqvrRRqlOkqQJsNbd1FV1N3DsyPjPDGJJkmbXOMeMz03ywkxd0yRJkmbVOGH8J3RfDPGzJLck+XGSWwauS5KkiTHOHbi22xiFSJI0qdYZxkmeNlN7VX1l9suRJGnyjHNp05tGhrcC9gYuAp4xSEWSJE2YcXZTv2B0PMkuwPsHq0iSpAkzzglc010LPHy2C5EkaVKNc8z4Q3R33YIuvPeiuxPXOiXZD/gAsAD4+6o6Zg3zvRA4A3h8VS0fZ92SJG0qxjlmPBqOdwL/XFUXrGuhJAvobhjyLLre9IVJllXVymnzbQf8GfAfY1ctSdImZJwwPgO4varugi5kk2xTVT9Zx3J7A1dV1ap+uVOBA4CV0+b7S+Cd3PtEMUmSJsZYd+ACth4Z3xr44hjLPQi4ZmT82r7tF5I8Ftilqj47xvokSdokjRPGW1XVrVMj/fA2G/rA/ZdQvBd4wxjzHpZkeZLlq1ev3tCHliRpThknjG/re7AAJHkc8NMxlrsO2GVkfOe+bcp2wCOB85N8D3gisCzJ0ukrqqrjq2ppVS1dtGjRGA8tSdL8Mc4x49cCpyf5PhDg14EXj7HchcDuSXajC+GDgD+cmth/+9PCqfEk5wNv9GxqSdKkGeemHxcmeRjw0L7pyqr6+RjL3ZnkcOAcukubPl5VK5IcDSyvqmUbUrgkSZuKca4zfjXwiaq6vB/fMcnBVXXcupatqrOBs6e1vX0N8+4zVsWSJG1ixjlm/MqqunlqpKpuAl45XEmSJE2WccJ4QZJMjfQ389hyuJIkSZos45zA9Tngk0k+2o//Sd8mSZJmwThh/GbgMOBP+/EvACcMVpEkSRNmnbupq+ruqvpIVR1YVQfS3c7yQ8OXJknSZBinZ0ySxwAHAy8CvgucOWRRkiRNkjWGcZI96AL4YOBG4JNAqup3NlJtkiRNhLX1jP8T+Crw/Kq6CiDJ6zZKVZIkTZC1HTP+feB64LwkJyR5Jt3tMCVJ0ixaYxhX1VlVdRDwMOA8untUPyDJ3yV59sYqUJKkTd04Z1PfVlWnVNUL6L556WK6y50kSdIsGOcOXL9QVTf1X2f4zKEKkiRp0qxXGEuSpNlnGEuS1JhhLElSY4axJEmNGcaSJDVmGEuS1JhhLElSY4axJEmNGcaSJDVmGEuS1JhhLElSY4axJEmNGcaSJDVmGEuS1JhhLElSY4axJEmNGcaSJDVmGEuS1JhhLElSY4axJEmNGcaSJDVmGEuS1JhhLElSY4axJEmNGcaSJDVmGEuS1JhhLElSY4axJEmNGcaSJDVmGEuS1JhhLElSY4axJEmNGcaSJDVmGEuS1JhhLElSY4axJEmNGcaSJDVmGEuS1JhhLElSY4OGcZL9klyZ5KokR84w/fVJVia5LMm5SRYPWY8kSXPRYGGcZAFwLPAcYE/g4CR7TpvtYmBpVf0WcAbwrqHqkSRprhqyZ7w3cFVVraqqO4BTgQNGZ6iq86rqJ/3o14GdB6xHkqQ5acgwfhBwzcj4tX3bmrwC+NcB65EkaU7avHUBAEleCiwFnr6G6YcBhwHsuuuuG7EySZKGN2TP+Dpgl5Hxnfu2e0myL/BWYP+q+tlMK6qq46tqaVUtXbRo0SDFSpLUypBhfCGwe5LdkmwJHAQsG50hyWOAj9IF8Q0D1iJJ0pw1WBhX1Z3A4cA5wBXAaVW1IsnRSfbvZ3s3sC1wepJLkixbw+okSdpkDXrMuKrOBs6e1vb2keF9h3x8SZLmA+/AJUlSY4axJEmNGcaSJDVmGEuS1JhhLElSY4axJEmNGcaSJDVmGEuS1JhhLElSY4axJEmNGcaSJDVmGEuS1JhhLElSY4axJEmNGcaSJDVmGEuS1JhhLElSY4axJEmNGcaSJDVmGEuS1JhhLElSY4axJEmNGcaSJDVmGEuS1JhhLElSY4axJEmNGcaSJDVmGEuS1JhhLElSY4axJEmNGcaSJDVmGEuS1JhhLElSY4axJEmNGcaSJDVmGEuS1JhhLElSY4axJEmNGcaSJDVmGEuS1JhhLElSY4axJEmNGcaSJDVmGEuS1JhhLElSY4axJEmNGcaSJDVmGEuS1JhhLElSY4axJEmNGcaSJDU2aBgn2S/JlUmuSnLkDNPvk+ST/fT/SLJkyHokSZqLBgvjJAuAY4HnAHsCByfZc9psrwBuqqrfBN4HvHOoeiRJmquG7BnvDVxVVauq6g7gVOCAafMcAJzUD58BPDNJBqxJkqQ5Z8gwfhBwzcj4tX3bjPNU1Z3Aj4D7D1iTJElzzuatCxhHksOAw/rRW5Nc2bKeeWYhcGPrIoYSD2zMNrcXrQ+3l/WzeE0Thgzj64BdRsZ37ttmmufaJJsDOwA/mL6iqjoeOH6gOjdpSZZX1dLWdWh+cHvR+nB7mT1D7qa+ENg9yW5JtgQOApZNm2cZ8LJ++EDgS1VVA9YkSdKcM1jPuKruTHI4cA6wAPh4Va1IcjSwvKqWAR8DTk5yFfBDusCWJGmixI7opi3JYf1ufmmd3F60PtxeZo9hLElSY94OU5KkxgzjgSW5K8klSVYkuTTJG5L8Sq97kqOT7LuW6a9KcsivXi0keVRf7yVJfpjku/3wFzdkvZrZyPZxeZJPJ7nfLK330CQfno11TVvv+f0tbqe2kQNn+zH6x1mS5A+HWPdck+TWWVjH0iQfXMv0e72e65p/huWn/u6XJrkwyV4bWvNsSbL/TLdbnm/cTT2wJLdW1bb98AOAU4ALquov2la2bklOBD5TVWdMa9+8v0mLNtC07eMk4NtV9dezsN5DgaVVdfiGrmvaes8H3lhVy9dzufXaZpLs0z/O89evwvlndBsY8DH2YQNez9G/e5KXA39YVc+ahboWVNVdG7qeTYE9442oqm6gu3nJ4eksSPLu/pPmZUn+ZGreJG9O8q3+k+gxfduJUz2RJMckWdkv97d921FJ3tgP75Xk6/30f0myY99+fpJ3JvlGkm8n+e1xau+Xe3+S5cCfJXlcki8nuSjJOUl26ud7SJLP9e1fTfKwWXwJN3Vfo79LXZK9k3wtycVJ/j3JQ/v2Q5Oc2b/G/5XkXVMLJ3l5/zf9BvCUkfYlSb7UbwvnJtm1bz8xyd/128mqJPsk+XiSK/oPYmNJ8mtJzurX//Ukv9W3H5Xk5CQX0F01sSjJp/rt/cIkT+nne/pIT/viJNsBxwC/3be9bkNf2PlmLf+/j+/bLunfOy7v2/dJ8pl+eJ2v57T5t03yD/37zWVJXriO8ka30/v228w3+sc6oG/fJslp/XvUv6T7IqCl/bRbk7wnyaXAk5K8tF/+kiQfTfe+uKDfPi/v63pdv+xrRt73Tu3bfrEXaB3b+gf7/6VVGWiPzgapKn8G/AFunaHtZuCBdMH8tr7tPsByYDe6L9f4d2Cbftqv9b9PpLse+/7AldyzZ+N+/e+j6D69AlwGPL0fPhp4fz98PvCefvi5wBfXUvuJwIEjyx3XD2/R17eoH38x3aVrAOcCu/fDT6C7drz532Gu/kxtH3SX/50O7NePbw9s3g/vC3yqHz4UWEV3g5ytgKvpbpyzE/DfwCJgS+AC4MP9Mp8GXtYP/zFw1sjf91QgdPeJvwV4FN2H9IuAvWao9/x+27uk/7k/8CHgL/rpzwAuGdkeLwK27sdPAZ7aD+8KXDFS31P64W3pLrnch26vTPO/0cbaBqa1ren/93LgSf3wMcDl/fAvXq9xXs9p879zav39+I5r+Lsv7YdfC/xNP/w3wEv74fsB3wbuC7wR+Gjf/kjgzpHlC3hRP/zwvt4t+vHjgEOAxwFfGHn8qfe47wP3mdZ26Jjb+un9tr0n3fcmNP/bj/7Mi9thbsKeDfzWyKe0HYDd6d58/6GqfgJQVT+cttyPgNuBj/Wfbj8zOjHJDnQb6pf7ppPoNsQpZ/a/LwKWrEe9n+x/P5TuH+wL6b7XYwFwfZJtgScDp+ee7/u4z3qsfxJtneQSup7GFcAX+vYdgJOS7E735rXFyDLnVtWPAJKspLvF3kLg/Kpa3bd/Etijn/9JwO/3wycD7xpZ16erqpJ8C/h/VfWtfvkVdNvGJTPU/JIa2U2d5KnACwGq6ktJ7p9k+37ysqr6aT+8L7DnyLaxfb/NXAC8N8kngDOr6tpM8PfFrOn/N935BNtV1df69lOAmXY7r+/ruS8j93ioqpvWMN8n0t3AaVtg6pjxs4H90++Ro/uAuCvwVOAD/fouT3LZyHruAj7VDz+TLngv7GvcGriBLlQfnORDwGeBz/fzX9bXcRZw1gw1rm1bP6uq7gZWJnngGp5jM4bxRpbkwXQb4w10PZIjquqcafP87trWUd0NVfam25APBA6n65GM62f977tYv23gtqkSgRVV9aTRif0b8M1VNWdO7pgHflpVeyXZhu4GOa8GPgj8JXBeVf1euu/5Pn9kmZ+NDK/v33C6qXXdPW29d2/geqfcNjK8GfDEqrp92jzHJPks3Z6aC9a1/Wvtqmqo1/MldB/g3023N+T36d4LXlhV9/q+gHWE/+11z3HiACdV1Vumz5Tk0cDvAq8CXkTX030e8DTgBcBbkzxqPeof3b7n3Kc9jxlvREkWAR+h26VSdG++f5pki376HknuS9c7enn/Bk2SX5u2nm2BHarqbOB1wKNHp/e9pptyz/HgPwK+zOy5EliU5El9PVskeURV3QJ8N8kf9O3p/6G0Dv1ekNcAb8g992mfupf7oWOs4j+Ap/e90i2APxiZ9u/c0/N5CfDVWSn6Hl/t1zt1otCN/bYw3eeBI6ZG0p+Rm+QhVfWtqnon3W10Hwb8GNhuluucF9b0/1tVNwM/TvKEvn3GOxb+Cq/nF+g+BE4tv+Naaivgz4Enpjsf5BzgiPTpm+Qx/awX0AUo6b7Hfk2heS5wYLqTW6fOP1icZCGwWVV9Cngb8Nh0V6HsUlXnAW+m+x+ZfuLb0Nv6YOwZD29qN+QWdMdNTgbe20/7e7pdgd/sN+bVwP+oqs/1b1TLk9wBnA3875F1bgf83yRb0X3Ce/0Mj/sy4CN9oK8CXj5bT6iq7uh3rX+w36W2OfB+YAXdP8DfJXlb/5xPBS6drcfelFXVxf3uvIPpdq+d1L+Onx1j2euTHEV3cs3N3Hv38hHAPyR5E902NmvbQu8o4ON97T/hnvvNT/ca4Nh+vs2Br9D1el6b5HfoeuMrgH/th+/qT/I5sareN8s1zyXbJLl2ZPy9rPn/9xXACUnupvuA/aMZ1rfO1xO4eGT+v6L7u1xOt6flHdxzKOuXVNVPk7wHeBPdXrn3A5f1Yfldul3nx9FtvyuB/+zr+KVaq2plv41/vl/+53QfDH5Kt81OdRjfQnc47J/695wAH6yqm6f1wofe1gfjpU2SNE8k2baqbu2HjwR2qqo/a1zWL0mygO6krNuTPAT4IvDQqrqjcWlzlj1jSZo/npfkLXTv3Vcz3iGMFrYBzusPmQT4Xwbx2tkzliSpMU/gkiSpMcNYkqTGDGNJkhozjCVJaswwliSpMcNYkqTG/j8nfKnas+5G6gAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ZfSfSwiaOIo"
      },
      "source": [
        "# Prediction on Test Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JvdC7axvadqr"
      },
      "source": [
        "### Selecting Logistic Regression model, because it has 91% accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "id": "AGwb-K0RaScM",
        "outputId": "640db92e-50da-4945-ab11-6e679806bcfb"
      },
      "source": [
        "df_test.head()"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>F1</th>\n",
              "      <th>F2</th>\n",
              "      <th>F3</th>\n",
              "      <th>F4</th>\n",
              "      <th>F5</th>\n",
              "      <th>F6</th>\n",
              "      <th>F7</th>\n",
              "      <th>F8</th>\n",
              "      <th>F9</th>\n",
              "      <th>F10</th>\n",
              "      <th>F11</th>\n",
              "      <th>F12</th>\n",
              "      <th>F13</th>\n",
              "      <th>F14</th>\n",
              "      <th>F15</th>\n",
              "      <th>Class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3</td>\n",
              "      <td>196.88</td>\n",
              "      <td>-31.74</td>\n",
              "      <td>-31.54</td>\n",
              "      <td>1.48</td>\n",
              "      <td>368.22</td>\n",
              "      <td>-0.90</td>\n",
              "      <td>-6.35</td>\n",
              "      <td>-12.63</td>\n",
              "      <td>1.64</td>\n",
              "      <td>-18.34</td>\n",
              "      <td>7.89</td>\n",
              "      <td>-3.77</td>\n",
              "      <td>10</td>\n",
              "      <td>8.81</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3</td>\n",
              "      <td>218.88</td>\n",
              "      <td>-33.51</td>\n",
              "      <td>-33.38</td>\n",
              "      <td>0.68</td>\n",
              "      <td>263.22</td>\n",
              "      <td>1.41</td>\n",
              "      <td>-6.80</td>\n",
              "      <td>-22.26</td>\n",
              "      <td>1.01</td>\n",
              "      <td>-22.90</td>\n",
              "      <td>7.89</td>\n",
              "      <td>-3.56</td>\n",
              "      <td>106</td>\n",
              "      <td>7.28</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>30</td>\n",
              "      <td>26.88</td>\n",
              "      <td>-24.09</td>\n",
              "      <td>-17.44</td>\n",
              "      <td>14.20</td>\n",
              "      <td>398.22</td>\n",
              "      <td>-4.38</td>\n",
              "      <td>-2.64</td>\n",
              "      <td>-12.69</td>\n",
              "      <td>8.00</td>\n",
              "      <td>-9.36</td>\n",
              "      <td>10.89</td>\n",
              "      <td>-8.19</td>\n",
              "      <td>60</td>\n",
              "      <td>6.52</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>30</td>\n",
              "      <td>286.88</td>\n",
              "      <td>-30.27</td>\n",
              "      <td>-17.42</td>\n",
              "      <td>10.00</td>\n",
              "      <td>338.22</td>\n",
              "      <td>-3.07</td>\n",
              "      <td>-2.65</td>\n",
              "      <td>-10.98</td>\n",
              "      <td>6.05</td>\n",
              "      <td>-10.68</td>\n",
              "      <td>20.89</td>\n",
              "      <td>-9.44</td>\n",
              "      <td>120</td>\n",
              "      <td>7.26</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>3</td>\n",
              "      <td>184.88</td>\n",
              "      <td>-32.22</td>\n",
              "      <td>-32.50</td>\n",
              "      <td>1.30</td>\n",
              "      <td>251.22</td>\n",
              "      <td>1.63</td>\n",
              "      <td>-6.75</td>\n",
              "      <td>-14.82</td>\n",
              "      <td>1.24</td>\n",
              "      <td>-25.94</td>\n",
              "      <td>7.89</td>\n",
              "      <td>-3.13</td>\n",
              "      <td>18</td>\n",
              "      <td>7.69</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    F1      F2     F3     F4     F5  ...    F12   F13  F14   F15  Class\n",
              "1    3  196.88 -31.74 -31.54   1.48  ...   7.89 -3.77   10  8.81    NaN\n",
              "4    3  218.88 -33.51 -33.38   0.68  ...   7.89 -3.56  106  7.28    NaN\n",
              "7   30   26.88 -24.09 -17.44  14.20  ...  10.89 -8.19   60  6.52    NaN\n",
              "8   30  286.88 -30.27 -17.42  10.00  ...  20.89 -9.44  120  7.26    NaN\n",
              "10   3  184.88 -32.22 -32.50   1.30  ...   7.89 -3.13   18  7.69    NaN\n",
              "\n",
              "[5 rows x 16 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_xxBrqN8bURD"
      },
      "source": [
        "X = df_test.drop('Class', axis=1)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8JkyCs6jbNiX"
      },
      "source": [
        "### Feature Scaling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yfR-E5C4bAYv"
      },
      "source": [
        "# data Scaling with sklearn\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# fit scaler on data\n",
        "scal = StandardScaler().fit(X)\n",
        "\n",
        "# transform data\n",
        "X_scal = scal.transform(X)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nkKuEWkpboH2"
      },
      "source": [
        "# Predict classes given the test features with Logistic Regression\n",
        "pred_y = cld_lr.predict(X_scal)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "id": "4640YiVkb0qs",
        "outputId": "e6700e26-8776-465e-ec9e-4161e860a4a1"
      },
      "source": [
        "# Setting Class column to predicted values\n",
        "X[\"Class\"] = pred_y\n",
        "X.head()"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>F1</th>\n",
              "      <th>F2</th>\n",
              "      <th>F3</th>\n",
              "      <th>F4</th>\n",
              "      <th>F5</th>\n",
              "      <th>F6</th>\n",
              "      <th>F7</th>\n",
              "      <th>F8</th>\n",
              "      <th>F9</th>\n",
              "      <th>F10</th>\n",
              "      <th>F11</th>\n",
              "      <th>F12</th>\n",
              "      <th>F13</th>\n",
              "      <th>F14</th>\n",
              "      <th>F15</th>\n",
              "      <th>Class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3</td>\n",
              "      <td>196.88</td>\n",
              "      <td>-31.74</td>\n",
              "      <td>-31.54</td>\n",
              "      <td>1.48</td>\n",
              "      <td>368.22</td>\n",
              "      <td>-0.90</td>\n",
              "      <td>-6.35</td>\n",
              "      <td>-12.63</td>\n",
              "      <td>1.64</td>\n",
              "      <td>-18.34</td>\n",
              "      <td>7.89</td>\n",
              "      <td>-3.77</td>\n",
              "      <td>10</td>\n",
              "      <td>8.81</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3</td>\n",
              "      <td>218.88</td>\n",
              "      <td>-33.51</td>\n",
              "      <td>-33.38</td>\n",
              "      <td>0.68</td>\n",
              "      <td>263.22</td>\n",
              "      <td>1.41</td>\n",
              "      <td>-6.80</td>\n",
              "      <td>-22.26</td>\n",
              "      <td>1.01</td>\n",
              "      <td>-22.90</td>\n",
              "      <td>7.89</td>\n",
              "      <td>-3.56</td>\n",
              "      <td>106</td>\n",
              "      <td>7.28</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>30</td>\n",
              "      <td>26.88</td>\n",
              "      <td>-24.09</td>\n",
              "      <td>-17.44</td>\n",
              "      <td>14.20</td>\n",
              "      <td>398.22</td>\n",
              "      <td>-4.38</td>\n",
              "      <td>-2.64</td>\n",
              "      <td>-12.69</td>\n",
              "      <td>8.00</td>\n",
              "      <td>-9.36</td>\n",
              "      <td>10.89</td>\n",
              "      <td>-8.19</td>\n",
              "      <td>60</td>\n",
              "      <td>6.52</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>30</td>\n",
              "      <td>286.88</td>\n",
              "      <td>-30.27</td>\n",
              "      <td>-17.42</td>\n",
              "      <td>10.00</td>\n",
              "      <td>338.22</td>\n",
              "      <td>-3.07</td>\n",
              "      <td>-2.65</td>\n",
              "      <td>-10.98</td>\n",
              "      <td>6.05</td>\n",
              "      <td>-10.68</td>\n",
              "      <td>20.89</td>\n",
              "      <td>-9.44</td>\n",
              "      <td>120</td>\n",
              "      <td>7.26</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>3</td>\n",
              "      <td>184.88</td>\n",
              "      <td>-32.22</td>\n",
              "      <td>-32.50</td>\n",
              "      <td>1.30</td>\n",
              "      <td>251.22</td>\n",
              "      <td>1.63</td>\n",
              "      <td>-6.75</td>\n",
              "      <td>-14.82</td>\n",
              "      <td>1.24</td>\n",
              "      <td>-25.94</td>\n",
              "      <td>7.89</td>\n",
              "      <td>-3.13</td>\n",
              "      <td>18</td>\n",
              "      <td>7.69</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    F1      F2     F3     F4     F5  ...    F12   F13  F14   F15  Class\n",
              "1    3  196.88 -31.74 -31.54   1.48  ...   7.89 -3.77   10  8.81   True\n",
              "4    3  218.88 -33.51 -33.38   0.68  ...   7.89 -3.56  106  7.28  False\n",
              "7   30   26.88 -24.09 -17.44  14.20  ...  10.89 -8.19   60  6.52  False\n",
              "8   30  286.88 -30.27 -17.42  10.00  ...  20.89 -9.44  120  7.26  False\n",
              "10   3  184.88 -32.22 -32.50   1.30  ...   7.89 -3.13   18  7.69  False\n",
              "\n",
              "[5 rows x 16 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A3a7xzZVcTAg"
      },
      "source": [
        "# Exporting Tested data as csv file\n",
        "X.to_csv(\"CE802_P2_Test.csv\", index = False)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lL0lAoy2_fGk"
      },
      "source": [
        ""
      ],
      "execution_count": 27,
      "outputs": []
    }
  ]
}